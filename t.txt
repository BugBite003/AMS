import React, { useRef, useState, useEffect } from "react";
import * as faceapi from "@vladmandic/face-api";

const FaceRecognition = () => {
    const videoRef = useRef(null);
    const [recognizedFace, setRecognizedFace] = useState(null);

    useEffect(() => {
        const loadModels = async () => {
            try {
                await Promise.all([
                    faceapi.nets.tinyFaceDetector.loadFromUri("/models"),
                    faceapi.nets.faceRecognitionNet.loadFromUri("/models"),
                    faceapi.nets.faceLandmark68Net.loadFromUri("/models"),
                    faceapi.nets.faceExpressionNet.loadFromUri("/models")
                ]);
                console.log("Models loaded successfully");
                startVideo();
                recognizeFace();
            } catch (error) {
                console.error("Error loading models:", error);
            }
        };

        loadModels();
    }, []);

    const startVideo = () => {
        navigator.mediaDevices.getUserMedia({ video: {} })
            .then((stream) => {
                videoRef.current.srcObject = stream;
            })
            .catch((err) => console.error("Error accessing webcam:", err));
    };

    const recognizeFace = async () => {
        const labeledDescriptors = await loadLabeledDescriptors();
        const faceMatcher = new faceapi.FaceMatcher(labeledDescriptors, 0.6);

        const canvas = faceapi.createCanvasFromMedia(videoRef.current);
        const displaySize = { width: videoRef.current.width, height: videoRef.current.height };
        faceapi.matchDimensions(canvas, displaySize);

        setInterval(async () => {
            const detections = await faceapi.detectAllFaces(videoRef.current, new faceapi.TinyFaceDetectorOptions()).withFaceLandmarks().withFaceDescriptors();
            const resizedDetections = faceapi.resizeResults(detections, displaySize);
            canvas.getContext("2d").clearRect(0, 0, canvas.width, canvas.height);
            const results = resizedDetections.map((d) => faceMatcher.findBestMatch(d.descriptor));
            const recognizedResult = results.find((result) => result.label === "Messi");

            if (recognizedResult) {
                setRecognizedFace("Messi");
            } else {
                setRecognizedFace(null);
            }

            faceapi.draw.drawDetections(canvas, resizedDetections);
        }, 100);
    };

    const loadLabeledDescriptors = async () => {
        const descriptors = [];
        const img = await faceapi.fetchImage("/Messi/1.jpg");
        const detections = await faceapi.detectSingleFace(img).withFaceLandmarks().withFaceDescriptor();
        descriptors.push(new faceapi.LabeledFaceDescriptors("Messi", [detections.descriptor]));
        return descriptors;
    };

    useEffect(() => {
        startVideo();
        setTimeout(recognizeFace, 1000);
    }, []);

    return (
        <div>
            <h1>Face Recognition</h1>
            <video ref={videoRef} autoPlay muted width="720" height="560" />
            {recognizedFace && <p>Recognized: {recognizedFace}</p>}
        </div>
    );
};

export default FaceRecognition;
